{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decorator_1(func):\n",
    "    def func_wrapper(x):\n",
    "        print('dec1')\n",
    "        func(x)\n",
    "        print('dec1')\n",
    "    return func_wrapper\n",
    "\n",
    "def decorator_2(func):\n",
    "    def func_wrapper(x):\n",
    "        print('dec2')\n",
    "        func(x)\n",
    "        print('dec2')\n",
    "    return func_wrapper\n",
    "\n",
    "@decorator_2\n",
    "@decorator_1\n",
    "def function_a(x):\n",
    "    print(x)\n",
    "\n",
    "function_a(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_f(name1):\n",
    "    print('hello {}'.format(name1))\n",
    "\n",
    "def mapper_f(kwargs):\n",
    "    return temp_f(**kwargs)\n",
    "\n",
    "mapper_f({'name1': 'lee'})\n",
    "(lambda kwargs: temp_f(**kwargs))({'name1': 'lee'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import ipyparallel as ipp\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "import logging # logging can create duplicate entries if you don't reload logging\n",
    "try:\n",
    "    from importlib import reload # Python 3\n",
    "except: # Python 2 reload is a builtin\n",
    "    pass\n",
    "\n",
    "class MultipleClusterEngine(object):\n",
    "    def __init__(self, cluster_job_name, n_cpus_list, input_file_names, output_parent_dir, function_to_process, function_kwargs_dict): # always put it in as a dictionary\n",
    "        reload(logging)\n",
    "        self.cluster_job_name = cluster_job_name\n",
    "        self.n_cpus_list = n_cpus_list\n",
    "        self.output_parent_dir = output_parent_dir\n",
    "        self.input_file_names = input_file_names\n",
    "        self.function_to_process = lambda kwargs: function_to_process(**kwargs)\n",
    "        self.function_kwargs_dict = function_kwargs_dict\n",
    "        \n",
    "        assert cluster_job_name, \"Needs cluster name\"\n",
    "        assert len(n_cpus_list) > 0, \"Needs the number of CPUs per cluster\"\n",
    "        assert os.path.isdir(self.output_parent_dir), \"Output directory doesn't exist\"\n",
    "        assert len(self.input_file_names) > 0, \"Need input files\"\n",
    "\n",
    "        # used by engine\n",
    "        self.client_dict = {}\n",
    "        self.load_balanced_view_dict = {}\n",
    "        self.async_results_dict = defaultdict(list) # collects all the async_results\n",
    "        self.file_to_cluster_order_dict = defaultdict(list) # remembers which file is sent to which cluster\n",
    "        self.cluster_indexes = None\n",
    "        self.logger_status = None\n",
    "        self.logger_failure = None\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.cluster_output_dir = None\n",
    "\n",
    "    def create_cluster_output_dir(self):\n",
    "        subdirs = [name for name in os.listdir(self.output_parent_dir) if \n",
    "                   os.path.isdir(os.path.join(self.output_parent_dir, name))]\n",
    "        existing_results_dir = []\n",
    "        for subdir in subdirs:\n",
    "            try:\n",
    "                existing_results_dir.append(int(subdir.strip(self.cluster_job_name)))\n",
    "            except ValueError:\n",
    "                pass\n",
    "        dir_index = max(existing_results_dir) + 1 if existing_results_dir else 0\n",
    "        self.cluster_output_dir = os.path.join(self.output_parent_dir, self.cluster_job_name + str(dir_index))\n",
    "        os.makedirs(self.cluster_output_dir)\n",
    "                \n",
    "    def create_logger(self, logger_name, log_file):\n",
    "        l = logging.getLogger(logger_name)\n",
    "        fileHandler = logging.FileHandler(log_file)\n",
    "        l.addHandler(fileHandler)\n",
    "        l.setLevel(logging.INFO)\n",
    "    \n",
    "    def activate_logger(self):\n",
    "        self.create_logger('status', os.path.join(self.cluster_output_dir, \"status.log\"))\n",
    "        self.create_logger('failure', os.path.join(self.cluster_output_dir, \"failure.log\"))\n",
    "        self.logger_status = logging.getLogger('status')\n",
    "        self.logger_status.propagate = False\n",
    "        self.logger_failure = logging.getLogger('failure')\n",
    "        self.logger_failure.propagate = False\n",
    "    \n",
    "    def start_cluster(self, n_cpus, cluster_id):\n",
    "        self.logger_status.info(\"\\tAttempting to start cluster job {}'s {}th cluster with {} CPUs\".format(self.cluster_job_name, cluster_id, n_cpus))\n",
    "        os.system(\"ipcluster start --n={} --profile={}{} --daemonize\".format(\n",
    "            n_cpus, self.cluster_job_name, cluster_id)) # should deprecate to use a safer bash call\n",
    "\n",
    "        attempt_ctr = 0 \n",
    "        while attempt_ctr < 3: # Attempt to connect to client 3 times\n",
    "            time.sleep(10) # hard coded\n",
    "            try:\n",
    "                client = ipp.Client(profile='{}{}'.format(self.cluster_job_name, cluster_id))\n",
    "            except ipp.error.TimeoutError:\n",
    "                attempt_ctr += 1\n",
    "            else:\n",
    "                self.logger_status.info('\\t\\tCPU processes ready for action: {}'.format(client[:].apply_async(os.getpid).get()))\n",
    "                return client\n",
    "            # if there is any other error other than TimeoutError, then the error will be raised\n",
    "            \n",
    "    def start_all_clusters(self):\n",
    "        self.activate_logger()\n",
    "        self.logger_status.info('Starting Multiple Cluster Engine')\n",
    "        #self.logger_status.info('Attempting to start all clusters')\n",
    "        for cluster_id, n_cpus in enumerate(self.n_cpus_list):\n",
    "            self.client_dict[cluster_id] = self.start_cluster(n_cpus, cluster_id)\n",
    "            self.load_balanced_view_dict[cluster_id] = self.client_dict[cluster_id].load_balanced_view()            \n",
    "        self.start_time = datetime.now()\n",
    "        self.logger_status.info('All clusters started at {}'.format(self.start_time))\n",
    "        self.cluster_indexes = itertools.cycle(sorted(self.load_balanced_view_dict))\n",
    "        \n",
    "    def kill_cluster(self, cluster_id): # use better arguments\n",
    "        # client = client_list[cluster_id]\n",
    "        self.logger_status.info('\\tAttempting to kill {}{} with CPU processes: {}'.format(\n",
    "            self.cluster_job_name, cluster_id, self.client_dict[cluster_id][:].apply_async(os.getpid).get()))\n",
    "        self.load_balanced_view_dict.pop(cluster_id)\n",
    "        # client.purge_everything()\n",
    "        self.client_dict[cluster_id].close()\n",
    "        os.system('ipcluster stop --profile={}{}'.format(self.cluster_job_name, cluster_id))\n",
    "        self.logger_status.info('\\t\\tCluster successfully killed')\n",
    "        time.sleep(5) # hard-coded\n",
    "        # have to mutate cluster_indexes\n",
    "        \n",
    "    def kill_all_clusters(self):\n",
    "        self.end_time = datetime.now()\n",
    "        self.logger_status.info('Killing all clusters')\n",
    "        for cluster_id in self.client_dict:\n",
    "            self.kill_cluster(cluster_id)\n",
    "        self.logger_status.info('All clusters have been killed')\n",
    "        self.logger_status.info('Multiple Cluster Engine shut down at {}'.format(self.end_time))\n",
    "        self.logger_status.info('Processed {} files in {} minutes'.format(\n",
    "            len(self.input_file_names), (self.end_time - self.start_time).seconds / 60.0))\n",
    "        logging.shutdown()\n",
    "\n",
    "    def create_kwargs_dict_list(self, input_file_name, cluster_id, n_cpus):\n",
    "        function_kwargs_dict = copy.deepcopy(self.function_kwargs_dict)\n",
    "        function_kwargs_dict.update({'input_file_name': input_file_name,\n",
    "                                    'cluster_output_dir': self.cluster_output_dir,\n",
    "                                    'cluster_id': cluster_id,\n",
    "                                    'n_cpus': n_cpus})\n",
    "        function_kwargs_dict_list = []\n",
    "        for cpu_id in range(n_cpus):\n",
    "            function_kwargs_dict_list.append(copy.deepcopy(function_kwargs_dict))\n",
    "            function_kwargs_dict_list[cpu_id]['cpu_id'] = cpu_id\n",
    "        return function_kwargs_dict_list \n",
    "    \n",
    "    def check_if_function_in_cluster_failured(self, jth_cluster):\n",
    "        if self.async_results_dict[jth_cluster] == []: # cluster just started, so it\n",
    "            return # doesn't have any files sent to the cluster yet\n",
    "        else:\n",
    "            exception = self.async_results_dict[jth_cluster][-1].exception()\n",
    "            if exception:\n",
    "                self.logger_failure.info('{}th cluster has error {} on file {}'.format(\n",
    "                    jth_cluster, exception.args[0], self.file_to_cluster_order_dict[jth_cluster][-1]))\n",
    "                                     \n",
    "    def run_clusters(self):\n",
    "        small_file_ctr = 1 # determine if you want to have queue or differently ordered queue\n",
    "        big_file_ctr = 0\n",
    "        \n",
    "        for ith_file in tqdm(range(len(self.input_file_names))):\n",
    "            for jth_cluster in self.cluster_indexes: # infinite loop\n",
    "                time.sleep(1) # hard coded delay time; want to do expected log time lag / number of clusters\n",
    "                ### insert code here to kill cluster if RAM usage too great, if possible log which file it was processing;\n",
    "                ### it has to do a global search of all clusters' RAM usage\n",
    "                ### would need a dictionary here to remember which cluster has which file; write to disk\n",
    "                ### profiler would also write to disk CPU usage what level\n",
    "\n",
    "                if (not self.async_results_dict[jth_cluster][-1:] \n",
    "                    or self.async_results_dict[jth_cluster][-1].done()): # check if cluster i is available                       \n",
    "                    # if necessary, recreate engine here if cluster shut down\n",
    "                    # clear cluster memory\n",
    "                    self.check_if_function_in_cluster_failured(jth_cluster) # check if previous file failed to process\n",
    "                    \n",
    "                    if jth_cluster == 0: # Send large files to large cluster (ALWAYS has id == 0)\n",
    "                        index = big_file_ctr\n",
    "                        big_file_ctr += 1\n",
    "                    else: # Send small files to small clusters (ALWAYS have id > 0)\n",
    "                        index = -small_file_ctr\n",
    "                        small_file_ctr += 1\n",
    "                                                                                   \n",
    "                    kwargs_dict_list = self.create_kwargs_dict_list(\n",
    "                        self.input_file_names[index],\n",
    "                        jth_cluster, \n",
    "                        len(self.client_dict[jth_cluster].ids))                    \n",
    "                    \n",
    "                    ### insert code to write results to file--it will only have start times, no end times\n",
    "                    async_result = self.load_balanced_view_dict[jth_cluster].map_async(\n",
    "                        self.function_to_process, # function name\n",
    "                        kwargs_dict_list\n",
    "#                            [self.input_file_names[index]] * len(self.client_dict[jth_cluster].ids), # file name, assumes first argument is always file name\n",
    "                            # [len(client_list[i].ids)] * len(client_list[i].ids), # number of CPUs, assumes second argument is always number of CPUs\n",
    "                            #  client_list[i].ids # CPU ids, assumes third argument is always CPU id; actually turn into kwargs\n",
    "                             # [output_folder_name] * len(client_list[i].ids) # assumes fourth argument is output directory\n",
    "#                            [self.function_kwargs_dict] * len(self.client_dict[jth_cluster].ids)                    \n",
    "                    #        [function_kwargs_dict] * len(self.client_dict[jth_cluster].ids)                    \n",
    "                            )                                              \n",
    "                    self.async_results_dict[jth_cluster].append(async_result)\n",
    "                    self.file_to_cluster_order_dict[jth_cluster].append(self.input_file_names[index])\n",
    "                    self.logger_status.info(\"{} is the {}th file and is sent to {}th cluster for processing\".format(\n",
    "                        self.input_file_names[index], ith_file, jth_cluster))\n",
    "                    break # break out of inner loop to determine if other clusters are available\n",
    "        while not all(self.async_results_dict[jth_cluster][-1].done() for jth_cluster in self.async_results_dict): # wait for all clusters to finish\n",
    "            time.sleep(1)\n",
    "        # async_results_dict; save to disk for later inspection?\n",
    "        \n",
    "    def main(self):\n",
    "        self.create_cluster_output_dir()\n",
    "        self.start_all_clusters()\n",
    "        self.run_clusters()\n",
    "        self.kill_all_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "        \n",
    "\n",
    "def silly_func(string_saved_to_file,\n",
    "             input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id # mandatory args, you can choose not to use them but function has to take them in \n",
    "):\n",
    "    import os # function has to import all the libraries it uses\n",
    "    with open(input_file_name, 'r') as in_:\n",
    "        text = ''.join(in_.readlines())        \n",
    "    output_file_name = '_'.join(['cluster' + str(cluster_id), 'cpu' + str(cpu_id), input_file_name.split('/')[-1]])\n",
    "    output_file_name = os.path.join(cluster_output_dir, output_file_name)\n",
    "    with open(output_file_name, 'w') as out_:\n",
    "        out_.write('My cluster_id is {}\\n'.format(cluster_id))\n",
    "        out_.write('The number of CPUs in this cluster is {}\\n'.format(n_cpus))\n",
    "        out_.write('My CPU_id is {}\\n'.format(cpu_id))\n",
    "        out_.write('My string is: {}\\n'.format(string_saved_to_file))\n",
    "\n",
    "mce_args = {\n",
    "    'cluster_job_name': 'write_to_file', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)], # absolute path prefered; I'm lazy\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, directory has to already exist\n",
    "    'function_to_process': silly_func,\n",
    "    'function_kwargs_dict': {'string_saved_to_file': 'pee-a-boo!'} # this can be crucial    \n",
    "    }\n",
    "\n",
    "mce = MultipleClusterEngine(**mce_args)\n",
    "# mce.start_all_clusters()\n",
    "# mce.run_clusters()\n",
    "mce.main()\n",
    "# mce.kill_all_clusters() if your function_to_process failed while clusters still alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce.kill_all_clusters() # if your function_to_process failed while clusters still alive\n",
    "# probably still have to take a look at the processes and manually kill the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "def error_func1(\n",
    "             input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id # mandatory args, you can choose not to use them but function has to take them in \n",
    "):\n",
    "    1 / 0\n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'write_to_file', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': error_func1,\n",
    "    'function_kwargs_dict': {} # error_func1 takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce1 = MultipleClusterEngine(**mce_args)\n",
    "mce1.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce1.kill_all_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "def error_func2(\n",
    "             input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id # mandatory args, you can choose not to use them but function has to take them in \n",
    "):\n",
    "    '1' + 2\n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'write_to_file', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': error_func2,\n",
    "    'function_kwargs_dict': {} # error_func2 takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce2 = MultipleClusterEngine(**mce_args)\n",
    "mce2.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultipleClusterEnginePrototype(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.RAM_limit_in_GB = pass   \n",
    "\n",
    "    def memory_profiler():\n",
    "        pass # if all clusters are dead, then raise Error with a message\n",
    "        \n",
    "    def early_kill():\n",
    "        pass # write file to failure disk, maybe also cluster i and num_cpus # RAM overload\n",
    "    \n",
    "    def cluster_release_memory():\n",
    "        # after each map/reducer step, use gc.collect()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cluster is killed, then cannot trust jth_cluster index--instead of load_balanced_list, use load_balanced_dict\n",
    "\n",
    "# check if all engines killed\n",
    "# RAM logger\n",
    "# figure out queue vs deque; deque is better\n",
    "# # write a crap load of documentation\n",
    "# write shell script for configuration and installation\n",
    "# probably no async or threading required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weakref\n",
    "# unittest with a mapper/reducer? after each map/reducer step, use gc.collect()\n",
    "\n",
    "# MCE works on files. Hence, if you don't have any datafiles, then just create some empty files\n",
    "# SSD for parallel reading (not HDD); determine if you are IO constrained\n",
    "# RAM usage is heavier in Python 3 than Python 2; though Python 3 memory management is better\n",
    "# during function failure: benefit (error type will be saved to failure.log) and weakness (it doesn't say what line code failed\n",
    "#     at so you have to debug your function outside of the MCE instance. You have to debug as if it were just calling\n",
    "#     the function by itself on some data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/donnemartin/data-science-ipython-notebooks/tree/master/mapreduce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
