{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All code run on AWS m4.2xlarge (8 CPUs and 32 GB of RAM) with Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi1 defaultdict(<class 'list'>, {0: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>>], 1: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>], 2: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>]})\n",
      "hi2 defaultdict(<class 'list'>, {0: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>], 1: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>], 2: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>]})\n",
      "hi3 defaultdict(<class 'list'>, {0: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>], 1: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>], 2: [<AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>, <AsyncMapResult: <lambda>:finished>]})\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "        \n",
    "\n",
    "def save_a_string(string_saved_to_file, # actual args used in this function\n",
    "    # mandatory args, you can choose not to use them but function has to take them in\n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id  \n",
    "):\n",
    "    import os # function has to import all the libraries it uses\n",
    "    with open(input_file_name, 'r') as in_:\n",
    "        text = ''.join(in_.readlines())        \n",
    "    output_file_name = '_'.join(['cluster' + str(cluster_id), 'cpu' + str(cpu_id), input_file_name.split('/')[-1]])\n",
    "    output_file_name = os.path.join(cluster_output_dir, output_file_name)\n",
    "    with open(output_file_name, 'w') as out_:\n",
    "        out_.write('My cluster_id is {}\\n'.format(cluster_id))\n",
    "        out_.write('The number of CPUs in this cluster is {}\\n'.format(n_cpus))\n",
    "        out_.write('My CPU_id is {}\\n'.format(cpu_id))\n",
    "        out_.write('My string is: {}\\n'.format(string_saved_to_file))\n",
    "\n",
    "mce_args = {\n",
    "    'cluster_job_name': 'save_a_silly_string', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)], # absolute path preferred; I'm lazy\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # absolute path preferred, directory has to already exist\n",
    "    'function_to_process': save_a_string,\n",
    "    'function_kwargs_dict': {'string_saved_to_file': 'pee-a-boo!'} # function arguments here\n",
    "    }\n",
    "\n",
    "mce = MultipleClusterEngine(**mce_args)\n",
    "# mce.start_all_clusters()\n",
    "# mce.run_clusters()\n",
    "mce.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             1: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             2: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>]})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce.async_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce.kill_all_clusters() # if your function_to_process failed while clusters still alive, then kill clusters manually\n",
    "# probably still have to take a look at the processes and manually kill the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "def error_func1( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in\n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id ):\n",
    "    1 / 0\n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'write_to_file', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': error_func1,\n",
    "    'function_kwargs_dict': {} # error_func1 takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce1 = MultipleClusterEngine(**mce_args)\n",
    "mce1.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             1: [],\n",
       "             2: []})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mce1.kill_all_clusters()\n",
    "mce1.async_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "\n",
    "def error_func2( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in \n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id):\n",
    "    '1' + 2\n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'write_to_file', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': error_func2,\n",
    "    'function_kwargs_dict': {} # error_func2 takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce2 = MultipleClusterEngine(**mce_args)\n",
    "mce2.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             1: [],\n",
       "             2: []})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mce2.kill_all_clusters()\n",
    "mce2.async_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "\n",
    "def exceed_memory_limit( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in \n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id):\n",
    "    import time\n",
    "    time.sleep(5)\n",
    "    if cluster_id % 2: # if cluster_id is odd, increase RAM usage until it is killed\n",
    "        exceed_ram_limit = []\n",
    "        current_value = 0\n",
    "        while True:\n",
    "            exceed_ram_limit.append(current_value)\n",
    "            current_value += 1\n",
    "    return cluster_id\n",
    "        \n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'write_to_file', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2, 1, 1, 1], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': exceed_memory_limit,\n",
    "    'function_kwargs_dict': {} # exceed_memory_limit takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce3 = MultipleClusterEngine(**mce_args)\n",
    "#mce3.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:09,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.202498048, 0.152977408, 0.103415808, 0.049614848]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:02<00:08,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.152977408, 0.103415808, 0.049614848]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:03<00:07,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.1558528, 0.103415808, 0.049614848]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:04<00:06,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp'], 2: ['8.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.1558528, 0.105299968, 0.049614848]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.1558528, 0.105299968, 0.050552832]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.1558528, 0.105299968, 0.050552832]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.1558528, 0.105299968, 0.050552832]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.891019264, 0.105299968, 0.050552832]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:09<00:09,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 1.653526528, 0.105299968, 0.050552832]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 2.579070976, 0.105299968, 0.437116928]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:11<00:07,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 3.7695488, 0.105299968, 0.838045696]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 4.953309184, 0.105299968, 1.236656128]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 6.146613248, 0.105299968, 1.640964096]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 7.3402368, 0.105299968, 2.04447744]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 8.522883072, 0.105299968, 2.44713472]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 9.711726592, 0.105299968, 2.848628736]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:17<00:07,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 10.899726336, 0.105299968, 3.249557504]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 12.0786944, 0.105299968, 3.650052096]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:19<00:04,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 13.272137728, 0.105299968, 4.054601728]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp', '5.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 14.45707776, 0.105299968, 4.455972864]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp', '5.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 15.636709376, 0.105299968, 4.859641856]) 20.0\n",
      "killing cluster1\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp', '5.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 5.51168]) 20.0\n",
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp', '5.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 5.911433216]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:24<00:02,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp', '5.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 6.31517184]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:25<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: ['0.tmp', '1.tmp', '2.tmp', '3.tmp'], 1: ['9.tmp'], 2: ['8.tmp', '6.tmp', '5.tmp'], 3: ['7.tmp']})\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 6.721204224]) 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 7.121350656]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 7.526100992]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 7.927701504]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 8.331911168]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 8.73422848]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 9.137426432]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 9.542447104]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 9.947738112]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 10.352828416]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 10.759053312]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 11.163803648]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 11.562377216]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 11.967393792]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 12.372955136]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 12.771106816]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 13.176127488]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 13.583511552]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 13.98880256]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 14.3941632]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 14.799724544]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 15.204745216]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 15.611858944]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 16.016949248]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 16.422510592]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 16.828071936]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 17.232551936]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 17.639395328]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 18.030395392]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 18.437779456]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 18.8433408]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 19.248361472]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 19.65365248]) 20.0\n",
      "ending of while loop body\n",
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.20637696, 0.105299968, 20.059213824]) 20.0\n",
      "killing cluster3\n",
      "ending of while loop body\n"
     ]
    }
   ],
   "source": [
    "mce3.create_cluster_output_dir()\n",
    "mce3.start_all_clusters()\n",
    "mce3.run_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mce3.cluster_RAM_use_dict, key=mce3.cluster_RAM_use_dict.get, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d9e3cd25b14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmce3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_to_cluster_order_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mce3.file_to_cluster_order_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function kill_cluster_if_ram_limit_exceeded called\n",
      "dict_values([0.180105216, 0.133926912, 0.09367552, 32.29243392]) 20.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-332e0bfd573c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmce3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill_cluster_if_ram_limit_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/multiple-cluster-engine-in-python3/multiple_cluster_engine.py\u001b[0m in \u001b[0;36mkill_cluster_if_ram_limit_exceeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m             cluster_id = sorted(self.cluster_RAM_use_dict, \n\u001b[1;32m    171\u001b[0m                                  key=self.cluster_RAM_use_dict.get, reverse=True)[0]\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_kill_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'killing cluster{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_balanced_view_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiple-cluster-engine-in-python3/multiple_cluster_engine.py\u001b[0m in \u001b[0;36mearly_kill_cluster\u001b[0;34m(self, cluster_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m         self.logger_failure.info(('Killing {}{} which was processing file {} '\n\u001b[1;32m    158\u001b[0m             \u001b[0;34m'due to exceeding RAM limit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_job_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m              cluster_id, self.file_to_cluster_order_dict[cluster_id][-1]))\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ipcluster stop --profile={}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_job_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mce3.kill_cluster_if_ram_limit_exceeded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce3.kill_all_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce3.client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce3.profile_memory_for_all_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.607870976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mce3.cluster_RAM_use_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 35, in <module>\n",
      "    from tornado.ioloop import PollIOLoop, PeriodicCallback\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 49, in <module>\n",
      "    from tornado.platform.auto import set_close_exec, Waker\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/auto.py\", line 39, in <module>\n",
      "    from tornado.platform.posix import set_close_exec, Waker\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/tornado/platform/posix.py\", line 21, in <module>\n",
      "    import fcntl\n",
      "ImportError: /home/ubuntu/anaconda2/envs/py36/lib/python3.6/lib-dynload/fcntl.cpython-36m-x86_64-linux-gnu.so: failed to map segment from shared object: Cannot allocate memory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/bin/ipcluster\", line 11, in <module>\n",
      "    load_entry_point('ipyparallel==6.1.1', 'console_scripts', 'ipcluster')()\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 572, in load_entry_point\n",
      "    return get_distribution(dist).load_entry_point(group, name)\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2755, in load_entry_point\n",
      "    return ep.load()\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2408, in load\n",
      "    return self.resolve()\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/pkg_resources/__init__.py\", line 2414, in resolve\n",
      "    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/ipyparallel/__init__.py\", line 17, in <module>\n",
      "    from .serialize import *\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/ipyparallel/serialize/__init__.py\", line 5, in <module>\n",
      "    from .serialize import (\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/ipyparallel/serialize/serialize.py\", line 26, in <module>\n",
      "    from jupyter_client.session import MAX_ITEMS, MAX_BYTES\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/jupyter_client/session.py\", line 56, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/__init__.py\", line 3, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 38, in <module>\n",
      "    from .minitornado.ioloop import PollIOLoop, PeriodicCallback\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/minitornado/ioloop.py\", line 61, in <module>\n",
      "    from .platform.auto import set_close_exec, Waker\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/minitornado/platform/auto.py\", line 34, in <module>\n",
      "    from .posix import set_close_exec, Waker\n",
      "  File \"/home/ubuntu/anaconda2/envs/py36/lib/python3.6/site-packages/zmq/eventloop/minitornado/platform/posix.py\", line 21, in <module>\n",
      "    import fcntl\n",
      "ImportError: /home/ubuntu/anaconda2/envs/py36/lib/python3.6/lib-dynload/fcntl.cpython-36m-x86_64-linux-gnu.so: failed to map segment from shared object: Cannot allocate memory\n"
     ]
    }
   ],
   "source": [
    "!ipcluster stop --profile write_to_file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: <ipyparallel.client.client.Client at 0x7f1a31116ba8>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce3.client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             1: [<AsyncMapResult: <lambda>>],\n",
       "             2: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             3: [<AsyncMapResult: <lambda>:finished>]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mce3.kill_all_clusters()\n",
    "mce3.async_results_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
