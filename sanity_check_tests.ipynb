{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All code run on AWS m4.2xlarge (8 CPUs and 32 GB of RAM) with Python 3.\n",
    "# Ran on Python 2 successfully. It appears that this code is Python 3 and 2 compliant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/ubuntu/cluster_results’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# first make the output directory\n",
    "!mkdir /home/ubuntu/cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "        \n",
    "\n",
    "def save_a_string(string_saved_to_file, # actual args used in this function\n",
    "    # mandatory args, you can choose not to use them but function has to take them in\n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id  \n",
    "):\n",
    "    import os # function has to import all the libraries it uses\n",
    "    with open(input_file_name, 'r') as in_:\n",
    "        text = ''.join(in_.readlines())        \n",
    "    output_file_name = '_'.join(['cluster' + str(cluster_id), 'cpu' + str(cpu_id), input_file_name.split('/')[-1]])\n",
    "    output_file_name = os.path.join(cluster_output_dir, output_file_name)\n",
    "    with open(output_file_name, 'w') as out_:\n",
    "        out_.write('My cluster_id is {}\\n'.format(cluster_id))\n",
    "        out_.write('The number of CPUs in this cluster is {}\\n'.format(n_cpus))\n",
    "        out_.write('My CPU_id is {}\\n'.format(cpu_id))\n",
    "        out_.write('My string is: {}\\n'.format(string_saved_to_file))\n",
    "\n",
    "mce_args = {\n",
    "    'cluster_job_name': 'save_a_silly_string_', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'wait_time_in_seconds': 1,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)], # absolute path preferred; I'm lazy\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # absolute path preferred, directory has to already exist\n",
    "    'function_to_process': save_a_string,\n",
    "    'function_kwargs_dict': {'string_saved_to_file': 'pee-a-boo!'} # function arguments here\n",
    "    }\n",
    "\n",
    "mce = MultipleClusterEngine(**mce_args)\n",
    "# mce.create_cluster_output_dir()\n",
    "# mce.start_all_clusters()\n",
    "# mce.run_clusters()\n",
    "# mce.kill_all_clusters()\n",
    "mce.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             1: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             2: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>]})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce.async_results_dict # contains the details of each AsyncResultObject such as time to complete, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mce.kill_all_clusters() # if your function_to_process failed while clusters still alive, then kill clusters manually\n",
    "# probably still have to take a look at the processes and manually kill the clusters using the following lines\n",
    "# to kill each of the 3 clusters\n",
    "# !ipcluster stop --profile save_to_string_0\n",
    "# !ipcluster stop --profile save_to_string_1\n",
    "# !ipcluster stop --profile save_to_string_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "\n",
    "\n",
    "def error_func1( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in\n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id ):\n",
    "    1 / 0\n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'error_one_', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'wait_time_in_seconds': 1,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': error_func1,\n",
    "    'function_kwargs_dict': {} # error_func1 takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce1 = MultipleClusterEngine(**mce_args)\n",
    "mce1.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {0: [], 1: [], 2: []})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mce1.kill_all_clusters()\n",
    "mce1.async_results_dict # when a function fails on a file, its async_result history is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "\n",
    "\n",
    "def error_func2( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in \n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id):\n",
    "    '1' + 2\n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'error_two_', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'wait_time_in_seconds': 1,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': error_func2,\n",
    "    'function_kwargs_dict': {} # error_func2 takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce2 = MultipleClusterEngine(**mce_args)\n",
    "mce2.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {0: [], 1: [], 2: []})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mce2.kill_all_clusters()\n",
    "mce2.async_results_dict # when a function fails on a file, its async_result history is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "\n",
    "    \n",
    "def exceed_memory_limit( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in \n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id):\n",
    "    import time\n",
    "    time.sleep(5)\n",
    "    if cluster_id % 2: # if cluster_id is odd, increase RAM usage until it is killed\n",
    "        exceed_ram_limit = []\n",
    "        current_value = 0\n",
    "        while True:\n",
    "            exceed_ram_limit.append(current_value)\n",
    "            current_value += 1\n",
    "    return cluster_id\n",
    "        \n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'exceed_memory_', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2, 1, 1, 1], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'wait_time_in_seconds': 1,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': exceed_memory_limit,\n",
    "    'function_kwargs_dict': {} # exceed_memory_limit takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce3 = MultipleClusterEngine(**mce_args)\n",
    "mce3.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             2: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>],\n",
       "             4: [<AsyncMapResult: <lambda>:finished>,\n",
       "              <AsyncMapResult: <lambda>:finished>]})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce3.async_results_dict # when a function fails due to exceeding memory limit, its async_result history is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:03<00:02,  1.97it/s]"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "All clusters have been killed prematurely",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc6f7d903208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmce4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultipleClusterEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmce_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmce4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# I'm expecting an Exception here due to killing all clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/multiple-cluster-engine-in-python3/multiple_cluster_engine.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_cluster_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_all_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill_all_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiple-cluster-engine-in-python3/multiple_cluster_engine.py\u001b[0m in \u001b[0;36mrun_clusters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time_in_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile_memory_for_all_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill_cluster_if_ram_limit_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                 \u001b[0mjth_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiple-cluster-engine-in-python3/multiple_cluster_engine.py\u001b[0m in \u001b[0;36mkill_cluster_if_ram_limit_exceeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m             self.logger_status.info((\"{}: All clusters have been killed prematurely \"\n\u001b[1;32m    194\u001b[0m                 \"(probably due to exceeding RAM limit)\").format(datetime.now()))\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All clusters have been killed prematurely'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_if_function_in_cluster_failed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjth_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: All clusters have been killed prematurely"
     ]
    }
   ],
   "source": [
    "from multiple_cluster_engine import MultipleClusterEngine\n",
    "\n",
    "# create some fake files\n",
    "for i in range(10):\n",
    "    !echo {i + 10} > {i}.tmp        \n",
    "\n",
    "\n",
    "def exceed_memory_limit_all( # this function takes no real args that are not mandatory\n",
    "    # mandatory args, you can choose not to use them but function has to take them in \n",
    "     input_file_name, cluster_output_dir, cluster_id, n_cpus, cpu_id):\n",
    "    import time\n",
    "    time.sleep(cluster_id * cpu_id)\n",
    "    exceed_ram_limit = []\n",
    "    current_value = 0\n",
    "    while True:\n",
    "        exceed_ram_limit.append(current_value)\n",
    "        current_value += 1\n",
    "    return cluster_id\n",
    "        \n",
    "    \n",
    "mce_args = {\n",
    "    'cluster_job_name': 'exceed_memory_all_', # no spaces as it will be part of directory name\n",
    "    'n_cpus_list': [4, 3, 2, 1, 1, 1], # 1st cluster is always the largest or equal to the other clusters\n",
    "    'ram_limit_in_GB': 20.0,\n",
    "    'wait_time_in_seconds': 1,\n",
    "    'input_file_names': ['{}.tmp'.format(i) for i in range(10)],\n",
    "    'output_parent_dir': '/home/ubuntu/cluster_results', # use absolute path since it's safer, has to already exist\n",
    "    'function_to_process': exceed_memory_limit_all,\n",
    "    'function_kwargs_dict': {} # exceed_memory_limit takes no additional arguments    \n",
    "    }\n",
    "\n",
    "mce4 = MultipleClusterEngine(**mce_args)\n",
    "mce4.main() # I'm expecting an Exception here due to killing all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mce4.async_results_dict # when a function fails due to exceeding memory limit, its async_result history is removed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
